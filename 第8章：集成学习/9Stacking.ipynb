{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Stacking（堆叠集成）详解\n",
    "\n",
    "**Stacking**（Stacked Generalization，堆叠泛化）是集成学习（Ensemble Learning）的一种高级方法。\n",
    "它通过**组合多个不同模型（基学习器）的预测结果**，再使用一个次级模型（元学习器）进行最终预测。\n",
    "\n",
    "---\n",
    "\n",
    "## 一、核心思想\n",
    "\n",
    "与Bagging和Boosting不同，Stacking不是简单地投票或平均，而是：\n",
    "1. **先训练一组多样化的基学习器**\n",
    "2. **再用它们的输出作为新特征**\n",
    "3. **训练一个次级学习器进行最终预测**\n",
    "\n",
    "这种方法能有效利用多个模型的不同优势。\n",
    "\n",
    "---\n",
    "\n",
    "## 二、算法流程\n",
    "\n",
    "以分类任务为例，简要步骤如下：\n",
    "\n",
    "1. **训练基学习器**\n",
    "   - 在训练集上拟合多个不同的模型（如逻辑回归、决策树、SVM）\n",
    "\n",
    "2. **生成元特征**\n",
    "   - 用每个基模型对样本预测（通常是预测概率）\n",
    "   - 将所有基模型的预测拼接成新特征矩阵\n",
    "\n",
    "3. **训练元学习器**\n",
    "   - 以基学习器的输出作为输入特征\n",
    "   - 以原始标签作为目标\n",
    "   - 训练一个新的模型（如逻辑回归、线性回归）\n",
    "\n",
    "4. **预测**\n",
    "   - 基学习器先对测试集生成预测\n",
    "   - 元学习器使用这些预测输出最终结果\n",
    "\n",
    "---\n",
    "\n",
    "## 三、示意图\n",
    "\n",
    "```\n",
    "原始特征\n",
    "     |\n",
    "-------------------------\n",
    "|    |    |    |        |\n",
    "模型1 模型2 模型3 ... 模型N (基学习器)\n",
    "|     |     |           |\n",
    "预测1 预测2 预测3      预测N\n",
    " \\     \\     \\          /\n",
    "  \\     \\     \\        /\n",
    "   ------拼接为新特征-------\n",
    "               |\n",
    "           元学习器\n",
    "               |\n",
    "          最终预测\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 四、Stacking与Voting区别\n",
    "\n",
    "| 特性             | Voting                | Stacking               |\n",
    "|------------------|-----------------------|------------------------|\n",
    "| 组合方式         | 投票或平均            | 元模型学习组合         |\n",
    "| 是否可学习权重   | 否（或简单权重）      | 是（通过元学习器）     |\n",
    "| 泛化能力         | 一般                 | 更强                  |\n",
    "| 实现难度         | 简单                 | 中等                  |\n",
    "\n",
    "---\n",
    "\n",
    "## 五、优缺点\n",
    "\n",
    "✅ **优点**\n",
    "- 能充分利用不同模型的互补性\n",
    "- 提高预测准确率\n",
    "- 灵活：基模型、元模型均可选\n",
    "\n",
    "❌ **缺点**\n",
    "- 实现比Bagging/Boosting复杂\n",
    "- 训练/预测速度慢\n",
    "- 容易过拟合（需交叉验证）\n",
    "\n",
    "---\n",
    "\n",
    "## 六、Python示例（scikit-learn）\n",
    "\n",
    "这里演示一个二分类任务：\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 加载数据\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# 定义基模型\n",
    "base_learners = [\n",
    "    ('lr', LogisticRegression(max_iter=200)),\n",
    "    ('dt', DecisionTreeClassifier(max_depth=3)),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5))\n",
    "]\n",
    "\n",
    "# 定义元模型\n",
    "meta_learner = LogisticRegression()\n",
    "\n",
    "# 构建Stacking\n",
    "stacking = StackingClassifier(\n",
    "    estimators=base_learners,\n",
    "    final_estimator=meta_learner,\n",
    "    passthrough=False,  # 如果为True，会把原始特征和预测拼接\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "stacking.fit(X_train, y_train)\n",
    "y_pred = stacking.predict(X_test)\n",
    "\n",
    "print(\"Stacking Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 七、实用技巧\n",
    "\n",
    "- **交叉验证**：生成元特征时要用交叉验证避免信息泄漏\n",
    "- **多样性**：基学习器应尽可能不同（模型、超参）\n",
    "- **元学习器**：通常用简单模型（如逻辑回归）\n",
    "- **调参**：需对基模型与元模型分别调参\n",
    "\n",
    "---\n",
    "\n",
    "## 八、常见应用\n",
    "\n",
    "- 比赛（Kaggle、天池）\n",
    "- 推荐系统\n",
    "- 金融风控\n",
    "\n",
    "---\n",
    "\n",
    "## 九、与其他集成对比\n",
    "\n",
    "| 方法            | 样本采样       | 特征采样       | 学习器依赖性     | 权重学习      |\n",
    "|-----------------|----------------|----------------|------------------|---------------|\n",
    "| Bagging         | 有（Bootstrap）| 无             | 无（并行）       | 无            |\n",
    "| Boosting        | 有（重加权）   | 无             | 有（串行）       | 有            |\n",
    "| Stacking        | 无              | 无             | 无（并行）       | 有（元学习器）|\n",
    "\n",
    "---\n",
    "\n",
    "## 十、总结\n",
    "\n",
    "**Stacking**：\n",
    "- 将不同模型的预测融合\n",
    "- 可显著提升性能\n",
    "- 是机器学习集成最强方法之一\n",
    "\n",
    "> **提示**：如果你有多种模型且它们表现相近，Stacking非常值得尝试。\n",
    "\n",
    "---"
   ],
   "id": "48544bcee19865e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T06:45:31.716900Z",
     "start_time": "2025-07-13T06:45:31.711782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ],
   "id": "4c44b69cb7076ab8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T06:45:31.734195Z",
     "start_time": "2025-07-13T06:45:31.729393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = np.loadtxt('data/wine.data', delimiter=',')\n",
    "X = data[:, 1:]\n",
    "y = data[:, 0:1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.ravel(), train_size=0.8, random_state=0)\n"
   ],
   "id": "89b2d57c3b336977",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T06:45:31.753417Z",
     "start_time": "2025-07-13T06:45:31.751152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "clf1 = KNeighborsClassifier(n_neighbors=5)\n",
    "clf2 = RandomForestClassifier(n_estimators=500, random_state=1)\n",
    "clf3 = GaussianNB()\n"
   ],
   "id": "c348352309861c12",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T06:45:31.767850Z",
     "start_time": "2025-07-13T06:45:31.765468Z"
    }
   },
   "cell_type": "code",
   "source": "lr = LogisticRegression()",
   "id": "1709b3a2ad026c2d",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T06:45:31.780241Z",
     "start_time": "2025-07-13T06:45:31.777670Z"
    }
   },
   "cell_type": "code",
   "source": "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3], meta_classifier=lr)",
   "id": "47eb542f9de1d7a5",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T06:45:32.226309Z",
     "start_time": "2025-07-13T06:45:31.793621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for model in (clf1, clf2, clf3, sclf):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(model.__class__.__name__, accuracy_score(y_test, y_pred))"
   ],
   "id": "7f4713bfdecf953a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier 0.8055555555555556\n",
      "RandomForestClassifier 0.9722222222222222\n",
      "GaussianNB 0.9166666666666666\n",
      "StackingClassifier 0.9722222222222222\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
