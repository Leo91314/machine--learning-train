{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 决策树剪枝：预剪枝与后剪枝详解\n",
    "\n",
    "## 一、引言\n",
    "\n",
    "决策树虽然具有良好的可解释性和建模效率，但在训练过程中容易出现**过拟合**，即模型在训练集上表现良好，但在测试集上泛化能力差。造成这一问题的主要原因是：树的结构过于复杂，对训练数据“记得太多”。\n",
    "\n",
    "**剪枝（Pruning）** 是防止过拟合的重要技术，主要包括两类：\n",
    "\n",
    "- **预剪枝（Pre-pruning）**\n",
    "- **后剪枝（Post-pruning）**\n",
    "\n",
    "本文将系统介绍这两种剪枝策略的原理、实现方法及优劣对比。\n",
    "\n",
    "---\n",
    "\n",
    "## 二、为何需要剪枝？\n",
    "\n",
    "构建决策树时，尤其是当每次划分使得信息增益率略微提升时，算法可能会不断划分，直到：\n",
    "\n",
    "- 所有样本完全分类；\n",
    "- 或者每个叶节点只有一个样本。\n",
    "\n",
    "这虽然能在训练集上达到 100% 准确率，但极易导致模型过于复杂，泛化能力差。\n",
    "\n",
    "剪枝的目的就是**去除冗余的分支结构**，保留对测试集预测有用的部分，提升整体模型的**泛化能力**。\n",
    "\n",
    "---\n",
    "\n",
    "## 三、预剪枝（Pre-pruning）\n",
    "\n",
    "### 1. 基本思想\n",
    "\n",
    "在构建树的过程中提前判断是否继续划分，如果不满足某些条件，则停止划分，直接将当前节点设为叶子节点。\n",
    "\n",
    "### 2. 常见预剪枝策略\n",
    "\n",
    "- **最小样本数限制**：若一个节点样本数量小于设定阈值，则不再划分。\n",
    "- **最大树深限制**：控制树的最大深度，限制模型复杂度。\n",
    "- **信息增益阈值**：若当前划分带来的信息增益小于某个阈值，则停止划分。\n",
    "- **最小纯度提升**：仅在样本纯度提升足够时才继续划分。\n",
    "- **交叉验证评估**：通过交叉验证评估划分是否能提升性能。\n",
    "\n",
    "### 3. 优缺点\n",
    "\n",
    "| 优点 | 缺点 |\n",
    "|------|------|\n",
    "| 构建过程高效，节省计算资源 | 可能提前终止，导致欠拟合 |\n",
    "| 模型结构简单，解释性强 | 易忽略潜在有价值的划分 |\n",
    "\n",
    "---\n",
    "\n",
    "## 四、后剪枝（Post-pruning）\n",
    "\n",
    "### 1. 基本思想\n",
    "\n",
    "先构建一棵“完全树”（即尽可能细致划分），然后自底向上地回溯，评估每个非叶子节点是否应该剪掉其子树，变为叶子节点。\n",
    "\n",
    "### 2. 常见后剪枝方法\n",
    "\n",
    "#### （1）基于验证集剪枝\n",
    "\n",
    "- 划分训练集与验证集；\n",
    "- 对每个非叶节点：\n",
    "  - 比较原子树与剪掉子树后的精度；\n",
    "  - 若剪枝后验证集性能更好，则进行剪枝。\n",
    "\n",
    "#### （2）最小错误剪枝（Reduced Error Pruning）\n",
    "\n",
    "- 假设将子树替换为叶子节点；\n",
    "- 若替换后在验证集上错误率降低或持平，则进行剪枝。\n",
    "\n",
    "#### （3）代价复杂度剪枝（Cost Complexity Pruning，CART专用）\n",
    "\n",
    "- 引入惩罚项 $begin:math:text$\\\\alpha$end:math:text$，优化以下目标：\n",
    "\n",
    "$$\n",
    "R_\\alpha(T) = R(T) + \\alpha \\cdot |T|\n",
    "$$\n",
    "\n",
    "其中：\n",
    "\n",
    "- $begin:math:text$ R(T) $end:math:text$：训练误差；\n",
    "- $begin:math:text$ |T| $end:math:text$：树的复杂度（叶子节点数）；\n",
    "- $begin:math:text$ \\\\alpha $end:math:text$：控制误差与复杂度的权衡。\n",
    "\n",
    "通过遍历不同 $begin:math:text$\\\\alpha$end:math:text$ 值，选出最佳子树。\n",
    "\n",
    "### 3. 优缺点\n",
    "\n",
    "| 优点 | 缺点 |\n",
    "|------|------|\n",
    "| 不易过早停止，模型表现更稳定 | 构建完全树耗费资源较多 |\n",
    "| 泛化能力更强 | 剪枝过程复杂，需要验证集或交叉验证 |\n",
    "\n",
    "---\n",
    "\n",
    "## 五、预剪枝 vs 后剪枝 对比总结\n",
    "\n",
    "| 比较维度     | 预剪枝（Pre-pruning）         | 后剪枝（Post-pruning）             |\n",
    "|--------------|-------------------------------|------------------------------------|\n",
    "| 剪枝时机     | 树构建过程中                  | 树构建完成后                       |\n",
    "| 执行方式     | 拒绝继续划分                  | 回溯地合并子树                     |\n",
    "| 计算开销     | 较小                           | 较大（需构建完整树）               |\n",
    "| 控制粒度     | 较粗，风险较大                | 更精细，更鲁棒                     |\n",
    "| 过拟合防止   | 效果中等，可能欠拟合          | 效果更好，泛化能力更强             |\n",
    "| 实际应用     | 实时决策系统（高性能要求）    | 脱机建模、精度要求高的场景         |\n",
    "\n",
    "---\n",
    "\n",
    "## 六、可视化示意\n",
    "\n",
    "### 原始决策树（未经剪枝）\n",
    "\n",
    "```\n",
    "                [收入 > 8000?]\n",
    "                /          \\\n",
    "              是            否\n",
    "            /                \\\n",
    "   [负债比 > 0.4?]        [信用评分 > 700?]\n",
    "     /        \\               /        \\\n",
    "   是          否         是            否\n",
    "[批准]      [拒绝]     [批准]        [拒绝]\n",
    "```\n",
    "\n",
    "### 后剪枝结果（剪掉右子树）\n",
    "\n",
    "```\n",
    "                [收入 > 8000?]\n",
    "                /          \\\n",
    "              是           [拒绝]\n",
    "            /\n",
    "   [负债比 > 0.4?]\n",
    "     /        \\\n",
    "   是          否\n",
    "[批准]      [拒绝]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 七、总结\n",
    "\n",
    "决策树剪枝是提高模型泛化能力的核心手段：\n",
    "\n",
    "- **预剪枝**：高效但可能过早停止，适合资源受限场景；\n",
    "- **后剪枝**：更稳定但计算成本高，适合精度优先任务。\n",
    "\n",
    "在实际应用中，可结合交叉验证、信息增益阈值、错误率评估等手段，选择最合适的剪枝策略，以构建**准确、稳定、简洁**的决策树模型。\n",
    "\n",
    "---\n",
    "\n",
    "## 八、参考文献\n",
    "\n",
    "1. Quinlan J.R. (1993). *C4.5: Programs for Machine Learning*. Morgan Kaufmann.\n",
    "2. Breiman L. et al. (1984). *Classification and Regression Trees*. Wadsworth.\n",
    "3. 周志华，《机器学习》，清华大学出版社，2016."
   ],
   "id": "5e18051ab19317b9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b88f65f0230d9a81"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
