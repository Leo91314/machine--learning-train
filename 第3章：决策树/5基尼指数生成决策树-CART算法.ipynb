{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 🌳 CART算法与基尼指数详解\n",
    "\n",
    "CART（Classification and Regression Tree）是一种既可用于分类也可用于回归的决策树算法。其分类部分以**基尼指数（Gini Index）**为划分标准，目标是构建一棵最优的二叉树。\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 核心思想\n",
    "\n",
    "- 使用 **基尼指数** 作为划分标准；\n",
    "- 每次选择使得基尼指数最小的划分方式；\n",
    "- 构建的是一棵 **二叉树**；\n",
    "- 支持分类与回归；\n",
    "- 可结合剪枝策略提升泛化性能。\n",
    "\n",
    "---\n",
    "\n",
    "## 📘 基尼指数定义（Gini Index）\n",
    "\n",
    "基尼指数是衡量集合纯度的一种指标。\n",
    "\n",
    "### 对一个数据集 $D$，其基尼指数定义为：\n",
    "\n",
    "$$\n",
    "\\text{Gini}(D) = 1 - \\sum_{k=1}^{K} p_k^2\n",
    "$$\n",
    "\n",
    "- $K$：类别总数\n",
    "- $p_k$：样本属于第 $k$ 类的概率\n",
    "\n",
    "当所有样本属于同一类时，Gini = 0（最纯），越接近 0 表示越纯净。\n",
    "\n",
    "---\n",
    "\n",
    "## 🔣 特征划分的基尼指数\n",
    "\n",
    "对一个特征 $A$ 的划分结果 $\\{D_1, D_2, ..., D_n\\}$，该划分的基尼指数为：\n",
    "\n",
    "$$\n",
    "\\text{Gini}_A(D) = \\sum_{i=1}^{n} \\frac{|D_i|}{|D|} \\cdot \\text{Gini}(D_i)\n",
    "$$\n",
    "\n",
    "目标是选择使 $\\text{Gini}_A(D)$ **最小的特征及划分点**。\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 CART分类树构建步骤\n",
    "\n",
    "1. **初始化**：设定训练集 $D$；\n",
    "2. **遍历所有特征及其可能划分点**；\n",
    "3. **计算基尼指数 $\\text{Gini}_A(D)$**；\n",
    "4. **选择最小的划分作为当前节点分裂依据**；\n",
    "5. 对左右子集递归构建子树；\n",
    "6. 结合剪枝算法优化结构。\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 与 ID3 / C4.5 对比\n",
    "\n",
    "| 特征              | ID3             | C4.5                  | CART                       |\n",
    "|-------------------|------------------|------------------------|----------------------------|\n",
    "| 划分标准           | 信息增益         | 信息增益率             | 基尼指数                   |\n",
    "| 树结构             | 多叉树           | 多叉树                 | 二叉树                     |\n",
    "| 可处理特征         | 离散             | 离散 + 连续            | 离散 + 连续                |\n",
    "| 回归任务           | ❌ 不支持        | ❌ 不支持               | ✅ 支持回归树              |\n",
    "| 剪枝               | 不支持           | 支持（后剪枝）         | 支持（预剪枝 + 后剪枝）   |\n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 回归树的构建（简要）\n",
    "\n",
    "- 不再使用基尼指数，而是采用**均方误差（MSE）**来划分：\n",
    "\n",
    "  $$\n",
    "  \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y})^2\n",
    "  $$\n",
    "\n",
    "- 在每个划分点寻找使 MSE 最小的划分；\n",
    "- 叶节点的预测值是子集样本的均值。\n",
    "\n",
    "---\n",
    "\n",
    "## ✂️ 剪枝策略（预剪枝与后剪枝）\n",
    "\n",
    "- **预剪枝**：在划分前评估是否值得继续划分；\n",
    "- **后剪枝**：先构建完整树，然后对某些子树进行简化；\n",
    "- 常用评估标准：**交叉验证误差、复杂度代价函数等**。\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 CART应用领域\n",
    "\n",
    "- 银行信用评分系统\n",
    "- 医疗风险评估\n",
    "- 客户分类与推荐系统\n",
    "- 销售预测与趋势建模\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 总结\n",
    "\n",
    "CART 是一种高效且功能全面的决策树算法：\n",
    "\n",
    "- 支持分类与回归；\n",
    "- 使用基尼指数可减少偏好；\n",
    "- 结构清晰，逻辑透明；\n",
    "- 适合需要可解释性的任务场景。"
   ],
   "id": "b8da1e79da98d0f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fe88a392be81fb99"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
