{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 朴素贝叶斯中的拉普拉斯修正（Laplace Smoothing）\n",
    "\n",
    "在使用朴素贝叶斯（Naive Bayes）分类器进行文本分类、垃圾邮件识别等任务时，经常会遇到**概率为 0 的问题**。这时，就需要用到**拉普拉斯修正**（也叫**加一平滑**）来解决这一问题。\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 为什么需要拉普拉斯修正？\n",
    "\n",
    "朴素贝叶斯模型中，条件概率通常按如下公式计算：\n",
    "\n",
    "```math\n",
    "P(x_i | C_k) = \\frac{N_{ik} + 1}{N_k + V}\n",
    "```\n",
    "其中：\n",
    "\n",
    "- `V` 表示词汇表（所有可能出现的词）的大小\n",
    "- 分子加 1，表示“每个词至少出现 1 次”\n",
    "- 分母加 `V`，保证概率归一化\n",
    "\n",
    "这被称为 **加一平滑（Add-one Smoothing）**。\n",
    "\n",
    "更通用的做法是加任意一个正数 α（称为 **Lidstone 平滑**）：\n",
    "\n",
    "```math\n",
    "P(x_i | C_k) = \\frac{N_{ik} + α}{N_k + αV}\n",
    "```\n",
    "当 α = 1 时，就是拉普拉斯修正。\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 示例\n",
    "\n",
    "假设我们的词汇表是：`[\"apple\", \"banana\", \"cherry\"]`，共有 3 个词，即 `V = 3`。\n",
    "\n",
    "在类别 `\"fruit\"` 中，统计如下：\n",
    "\n",
    "- `\"apple\"` 出现 3 次\n",
    "- `\"banana\"` 出现 2 次\n",
    "- `\"cherry\"` 没出现（次数为 0）\n",
    "- 总词数为 5，即 `N(c) = 5`\n",
    "\n",
    "如果不使用拉普拉斯修正，`P(\"cherry\" | \"fruit\") = 0 / 5 = 0`。\n",
    "\n",
    "使用拉普拉斯修正后：\n",
    "\n",
    "```python\n",
    "P(\"cherry\" | \"fruit\") = (0 + 1) / (5 + 3) = 1 / 8 = 0.125\n",
    "```\n",
    "这样就避免了 0 概率的问题。\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙ 应用意义\n",
    "\n",
    "- ✅ **避免零概率**：保证每个特征在每个类别下都有非零概率。\n",
    "- 🛡️ **提高鲁棒性**：增强模型对未见过特征的适应能力。\n",
    "- 📊 **适用于稀疏数据场景**：尤其在文本分类、高维特征下效果显著。\n",
    "\n",
    "---\n",
    "\n",
    "## 📚 延伸阅读\n",
    "\n",
    "- 加权平滑（Lidstone Smoothing）\n",
    "- Kneser-Ney 平滑（用于语言模型）\n",
    "- Scikit-learn 中 `MultinomialNB` 的 `alpha` 参数控制平滑强度"
   ],
   "id": "60204eb58c00eb4f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def Train(train_set,train_labels):\n",
    "    m = train_set.shape[0]#样本数\n",
    "    n = train_set.shape[1]#特征数\n",
    "    prior_probability = {}#存储先验概率，key上类别值，value为概率\n",
    "    conditional_probability = {}\n",
    "    labels = set(train_labels)\n",
    "    for label in labels:\n",
    "        # prior_probability[label] = len(train_labels[train_labels == label])修正前\n",
    "        prior_probability[label] = len(train_labels[train_labels == label])+1\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            key = str(train_labels[i])+','+str(j)+','+str(train_set[i][j])\n",
    "            if key in conditional_probability:\n",
    "                conditional_probability[key] += 1\n",
    "            else:\n",
    "                conditional_probability[key] = 1\n",
    "    conditional_probability_final = {}\n",
    "    for key in conditional_probability:\n",
    "        # label = key.split(',')[0]\n",
    "        # conditional_probability_final[key] = conditional_probability[key]/prior_probability[int(label)]\n",
    "        conditional_probability[key] = conditional_probability[key]+1\n",
    "        key1 = int(key.split(','))\n",
    "        Ni = len(set(train_set[:,key1]))\n",
    "        label = key.split(',')[0]\n",
    "        conditional_probability_final[key] = conditional_probability[key]/prior_probability[int(label)]+Ni\n",
    "    for label in labels:\n",
    "        prior_probability[label] = prior_probability[label]/m\n",
    "    return prior_probability,conditional_probability_final, labels\n"
   ],
   "id": "103b532da0463139"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
