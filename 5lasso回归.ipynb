{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Lasso 回归（Lasso Regression）\n",
    "Lasso回归（Least Absolute Shrinkage and Selection Operator）是一种线性回归方法，通过在损失函数中引入 L1 正则化项 来防止模型过拟合。它不仅能提升模型泛化能力，还能实现特征选择。\n",
    "\n",
    "1. 目标函数 (Objective Function)\n",
    "Lasso回归的目标是最小化以下损失函数：\n",
    "$$ J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)})^2 + \\frac{\\lambda}{2m} \\sum_{j=1}^{n} |\\theta_j| $$\n",
    "其中：\n",
    "$ h_\\theta(x) $：假设函数，即预测值；\n",
    "$ m $：样本数量；\n",
    "$ n $：特征数量（不包括偏置项）；\n",
    "$ \\lambda $：正则化参数，控制惩罚强度（$\\lambda > 0$）；\n",
    "$ \\theta_j $：模型参数（权重）；\n",
    "$ x^{(i)} $：第 $ i $ 个样本的输入特征；\n",
    "$ y^{(i)} $：第 $ i $ 个样本的真实值。\n",
    "假设函数形式\n",
    "对于多元线性回归，假设函数为：\n",
    "$$ h_\\theta(x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\dots + \\theta_n x_n = \\sum_{j=0}^{n} \\theta_j x_j $$\n",
    "其中 $ x_0 = 1 $，作为偏置项。\n",
    "\n",
    "2. 求解方式（无解析解）\n",
    "与岭回归不同，Lasso回归的目标函数由于含有绝对值项（不可导），无法直接求出闭式解。通常采用以下优化方法进行求解：\n",
    "梯度下降法（Gradient Descent）\n",
    "坐标下降法（Coordinate Descent）\n",
    "最小角回归（LARS, Least Angle Regression）\n",
    "\n",
    "3. 梯度下降更新规则（Gradient Descent Update Rule）\n",
    "由于L1正则项在零点不可导，通常使用次梯度（subgradient）来处理。参数更新规则如下：\n",
    "对于 $ j = 0 $（偏置项）：\n",
    "$$ \\theta_0 := \\theta_0 - \\alpha \\cdot \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x_0^{(i)} $$\n",
    "对于 $ j = 1, 2, ..., n $（非偏置项）：\n",
    "$$ \\theta_j := \\theta_j - \\alpha \\cdot \\left( \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x_j^{(i)} + \\frac{\\lambda}{m} \\cdot \\text{sign}(\\theta_j) \\right) $$\n",
    "其中：\n",
    "$ \\alpha $：学习率；\n",
    "$ \\text{sign}(\\theta_j) $：符号函数，表示 $ \\theta_j $ 的正负号（当 $ \\theta_j = 0 $ 时可取任意值）；\n",
    "其余变量定义同上。\n",
    "\n",
    "4. 向量化形式（Vectorized Form）\n",
    "在实际代码实现中，可以将参数更新写成向量化形式以提高效率：\n",
    "$$ \\theta := \\theta - \\alpha \\cdot \\left( \\frac{1}{m} X^T (X\\theta - y) + \\frac{\\lambda}{m} \\cdot \\text{sign}(\\theta[1:]) \\right) $$\n",
    "注意：偏置项 $ \\theta_0 $ 不参与正则化。"
   ],
   "id": "1115af63c9b2e019"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "\n",
    "def lasso_regression_gradient_descent(X, y, theta, learning_rate=0.01, num_iterations=1000, lambda_=1.0):\n",
    "    m = X.shape[0]  # 样本数量\n",
    "    costs = np.zeros(num_iterations)\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        predictions = X @ theta\n",
    "        errors = predictions - y\n",
    "        gradient = (X.T @ errors) / m\n",
    "        sign_theta = np.sign(theta)\n",
    "        sign_theta[0] = 0  # 偏置项不加正则化\n",
    "        gradient += (lambda_ / m) * sign_theta\n",
    "        theta -= learning_rate * gradient\n",
    "        costs[i] = np.sum(errors**2) / (2*m) + (lambda_ / (2*m)) * np.sum(np.abs(theta[1:]))\n",
    "    return theta, costs\n"
   ],
   "id": "917110d49a0f3dc7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
